{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8c358-fd02-4d7b-a9db-6d5bb9bf4188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.0.0-cp312-cp312-macosx_12_0_arm64.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "Successfully installed datasets-3.0.2 multiprocess-0.70.16 pyarrow-18.0.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fbc661-1c81-42e9-8a6d-c56d5a8aad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f157e3-981a-4787-8322-5a2ead0804c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d811985f2c741298d15600f4c4529a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855cbcdfd645477d9e83feed26570837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9bbe8f50174fcb8fe243aaa40fa00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24abccf9c3ec4400b6d21438fe23a7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d7c41cb2b942ac9e6f46c10e42d3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f0a216b3544bd59a36cfc5a6625f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22282d4b41149dca3ab7f819357390d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ade63b-ca74-4973-af2f-b356aef66c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  label\n",
      "0   lovingly photographed in the manner of a golde...      1\n",
      "1               consistently clever and suspenseful .      1\n",
      "2   it's like a \" big chill \" reunion of the baade...      1\n",
      "3   the story gives ample opportunity for large-sc...      1\n",
      "4                   red dragon \" never cuts corners .      1\n",
      "5   fresnadillo has something serious to say about...      1\n",
      "6   throws in enough clever and unexpected twists ...      1\n",
      "7   weighty and ponderous but every bit as filling...      1\n",
      "8   a real audience-pleaser that will strike a cho...      1\n",
      "9   generates an enormous feeling of empathy for i...      1\n",
      "10  exposing the ways we fool ourselves is one hou...      1\n",
      "11  it's up to you to decide whether to admire the...      1\n",
      "12  mostly , [goldbacher] just lets her complicate...      1\n",
      "13  . . . quite good at providing some good old fa...      1\n",
      "14  at its worst , the movie is pretty diverting ;...      1\n",
      "{'text': ['lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'consistently clever and suspenseful .', 'it\\'s like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .', 'the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .', 'red dragon \" never cuts corners .', 'fresnadillo has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense .', 'throws in enough clever and unexpected twists to make the formula feel fresh .', 'weighty and ponderous but every bit as filling as the treat of the title .', \"a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\", 'generates an enormous feeling of empathy for its characters .', \"exposing the ways we fool ourselves is one hour photo's real strength .\", \"it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful view of american life .\", 'mostly , [goldbacher] just lets her complicated characters be unruly , confusing and , through it all , human .', '. . . quite good at providing some good old fashioned spooks .', 'at its worst , the movie is pretty diverting ; the pity is that it rarely achieves its best .'], 'label': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_dataset.to_pandas().head(15))\n",
    "\n",
    "print(test_dataset[:15])  # View the first 5 rows as a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc6a14-2a1b-4c18-a271-047bd4414647",
   "metadata": {},
   "source": [
    "# Google Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67690c1a-a274-4abf-b6fb-7d628b61d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Path to the .bin file\n",
    "# model_path = 'GoogleNews-vectors-negative300.bin'  # Update with the exact path to the .bin file\n",
    "\n",
    "# # Load the Word2Vec model\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "# print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10a49d-ad95-444e-842e-3d4c952b6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Define the model path\n",
    "model_name = \"word2vec-google-news-300\"\n",
    "model_path = f\"{model_name}.bin\"\n",
    "\n",
    "# Check if the model file already exists\n",
    "if not os.path.exists(model_path):\n",
    "    # Download the model\n",
    "    path = api.load(model_name, return_path=True)\n",
    "    print(f\"Model downloaded and saved at: {path}\")\n",
    "else:\n",
    "    print(f\"Model already exists at: {model_path}\")\n",
    "\n",
    "# Load the model\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "677787bc-b346-4868-b40f-e080afb3bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'king':\n",
      "kings: 0.7138\n",
      "queen: 0.6511\n",
      "monarch: 0.6413\n",
      "crown_prince: 0.6204\n",
      "prince: 0.6160\n",
      "sultan: 0.5865\n",
      "ruler: 0.5798\n",
      "princes: 0.5647\n",
      "Prince_Paras: 0.5433\n",
      "throne: 0.5422\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to \"king\"\n",
    "similar_words = word2vec_model.most_similar(\"king\", topn=10)\n",
    "print(\"Words similar to 'king':\")\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3872da37-9aaa-4cde-a2ff-bd55cd12e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'king' and 'queen': 0.6511\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity between \"king\" and \"queen\"\n",
    "similarity = word2vec_model.similarity(\"king\", \"queen\")\n",
    "print(f\"Similarity between 'king' and 'queen': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea02728-46a8-4830-a059-59f7cd5817ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'apple': [-0.06445312 -0.16015625 -0.01208496  0.13476562 -0.22949219  0.16210938\n",
      "  0.3046875  -0.1796875  -0.12109375  0.25390625 -0.01428223 -0.06396484\n",
      " -0.08056641 -0.05688477 -0.19628906  0.2890625  -0.05151367  0.14257812\n",
      " -0.10498047 -0.04736328 -0.34765625  0.35742188  0.265625    0.00188446\n",
      " -0.01586914  0.00195312 -0.35546875  0.22167969  0.05761719  0.15917969\n",
      "  0.08691406 -0.0267334  -0.04785156  0.23925781 -0.05981445  0.0378418\n",
      "  0.17382812 -0.41796875  0.2890625   0.32617188  0.02429199 -0.01647949\n",
      " -0.06494141 -0.08886719  0.07666016 -0.15136719  0.05249023 -0.04199219\n",
      " -0.05419922  0.00108337 -0.20117188  0.12304688  0.09228516  0.10449219\n",
      " -0.00408936 -0.04199219  0.01409912 -0.02111816 -0.13476562 -0.24316406\n",
      "  0.16015625 -0.06689453 -0.08984375 -0.07177734 -0.00595093 -0.00482178\n",
      " -0.00089264 -0.30664062 -0.0625      0.07958984 -0.00909424 -0.04492188\n",
      "  0.09960938 -0.33398438 -0.3984375   0.05541992 -0.06689453 -0.04467773\n",
      "  0.11767578 -0.13964844 -0.26367188  0.17480469 -0.17382812 -0.40625\n",
      " -0.06738281 -0.07617188  0.09423828  0.20996094 -0.16308594 -0.08691406\n",
      " -0.0534668  -0.10351562 -0.07617188 -0.11083984 -0.03515625 -0.14941406\n",
      "  0.0378418   0.38671875  0.14160156 -0.2890625  -0.16894531 -0.140625\n",
      " -0.04174805  0.22753906  0.24023438 -0.01599121 -0.06787109  0.21875\n",
      " -0.42382812 -0.5625     -0.49414062 -0.3359375   0.13378906  0.01141357\n",
      "  0.13671875  0.0324707   0.06835938 -0.27539062 -0.15917969  0.00121307\n",
      "  0.01208496 -0.0039978   0.00442505 -0.04541016  0.08642578  0.09960938\n",
      " -0.04296875 -0.11328125  0.13867188  0.41796875 -0.28320312 -0.07373047\n",
      " -0.11425781  0.08691406 -0.02148438  0.328125   -0.07373047 -0.01348877\n",
      "  0.17773438 -0.02624512  0.13378906 -0.11132812 -0.12792969 -0.12792969\n",
      "  0.18945312 -0.13867188  0.29882812 -0.07714844 -0.37695312 -0.10351562\n",
      "  0.16992188 -0.10742188 -0.29882812  0.00866699 -0.27734375 -0.20996094\n",
      " -0.1796875  -0.19628906 -0.22167969  0.08886719 -0.27734375 -0.13964844\n",
      "  0.15917969  0.03637695  0.03320312 -0.08105469  0.25390625 -0.08691406\n",
      " -0.21289062 -0.18945312 -0.22363281  0.06542969 -0.16601562  0.08837891\n",
      " -0.359375   -0.09863281  0.35546875 -0.00741577  0.19042969  0.16992188\n",
      " -0.06005859 -0.20605469  0.08105469  0.12988281 -0.01135254  0.33203125\n",
      " -0.08691406  0.27539062 -0.03271484  0.12011719 -0.0625      0.1953125\n",
      " -0.10986328 -0.11767578  0.20996094  0.19921875  0.02954102 -0.16015625\n",
      "  0.00276184 -0.01367188  0.03442383 -0.19335938  0.00352478 -0.06542969\n",
      " -0.05566406  0.09423828  0.29296875  0.04052734 -0.09326172 -0.10107422\n",
      " -0.27539062  0.04394531 -0.07275391  0.13867188  0.02380371  0.13085938\n",
      "  0.00236511 -0.2265625   0.34765625  0.13574219  0.05224609  0.18164062\n",
      "  0.0402832   0.23730469 -0.16992188  0.10058594  0.03833008  0.10839844\n",
      " -0.05615234 -0.00946045  0.14550781 -0.30078125 -0.32226562  0.18847656\n",
      " -0.40234375 -0.3125     -0.08007812 -0.26757812  0.16699219  0.07324219\n",
      "  0.06347656  0.06591797  0.17285156 -0.17773438  0.00276184 -0.05761719\n",
      " -0.2265625  -0.19628906  0.09667969  0.13769531 -0.49414062 -0.27929688\n",
      "  0.12304688 -0.30078125  0.01293945 -0.1875     -0.20898438 -0.1796875\n",
      " -0.16015625 -0.03295898  0.00976562  0.25390625 -0.25195312  0.00210571\n",
      "  0.04296875  0.01184082 -0.20605469  0.24804688 -0.203125   -0.17773438\n",
      "  0.07275391  0.04541016  0.21679688 -0.2109375   0.14550781 -0.16210938\n",
      "  0.20410156 -0.19628906 -0.35742188  0.35742188 -0.11962891  0.35742188\n",
      "  0.10351562  0.07080078 -0.24707031 -0.10449219 -0.19238281  0.1484375\n",
      "  0.00057983  0.296875   -0.12695312 -0.03979492  0.13183594 -0.16601562\n",
      "  0.125       0.05126953 -0.14941406  0.13671875 -0.02075195  0.34375   ]\n"
     ]
    }
   ],
   "source": [
    "# Get the vector for the word \"apple\"\n",
    "vector = word2vec_model[\"apple\"]\n",
    "print(\"Vector for 'apple':\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdba58f-ad61-4fbe-b87d-35f1db47d633",
   "metadata": {},
   "source": [
    "# GLOVE Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13fd9a36-85fb-4cd1-afcc-22a45eb02aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to your .pickle file\n",
    "glove_path = 'glove-wiki-gigaword-300.pickle'  # Replace with the actual file path\n",
    "\n",
    "# Load the GloVe model from the pickle file\n",
    "with open(glove_path, 'rb') as file:\n",
    "    glove_model = pickle.load(file)\n",
    "\n",
    "print(\"GloVe model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dadfe6d-6282-41e2-ab17-80c72cd51661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'king':\n",
      "queen: 0.6336\n",
      "prince: 0.6197\n",
      "monarch: 0.5900\n",
      "kingdom: 0.5791\n",
      "throne: 0.5606\n",
      "ii: 0.5562\n",
      "iii: 0.5503\n",
      "crown: 0.5225\n",
      "reign: 0.5217\n",
      "kings: 0.5066\n",
      "\n",
      "Similarity between 'king' and 'queen': 0.6336\n",
      "\n",
      "Analogy result for 'king - man + woman': [('queen', 0.6713277101516724)]\n",
      "\n",
      "'apple' is in the vocabulary.\n",
      "\n",
      "Vector for 'apple': [-0.20842   -0.019668   0.063981  -0.71403   -0.21181   -0.59283\n",
      " -0.15316    0.044217   0.63289   -0.84821   -0.21129   -0.19763\n",
      "  0.19029   -0.56226    0.27126    0.23782   -0.5189    -0.24518\n",
      "  0.035243   0.096833   0.24898    0.71279    0.038279  -0.10514\n",
      " -0.4779    -0.39515   -0.27194   -0.44428    0.06113   -0.2318\n",
      " -0.35901   -0.18239    0.035507  -0.087719  -1.0816    -0.42521\n",
      "  0.003224  -0.45991   -0.043462  -0.39031    0.519      0.21139\n",
      " -0.25527    1.1805    -0.19041   -0.12156    0.034186  -0.062316\n",
      "  0.14421   -0.53366    0.47425   -0.4471     0.58047    0.43578\n",
      "  0.1321    -0.095712  -0.37182   -0.013837   0.20601   -0.10099\n",
      "  0.10685   -0.33723    0.10986    0.34796   -0.099839   0.36942\n",
      " -0.52917    0.12407   -0.46127   -0.38483   -0.10114   -0.17634\n",
      "  0.37574    0.16377   -0.2198    -0.26841    0.84706   -0.35619\n",
      " -0.083992  -0.20276   -0.56542    0.19112   -0.14134   -0.7812\n",
      "  0.69188   -0.083628  -0.54293    0.16437    0.037606  -0.68896\n",
      " -0.68711   -0.13367   -0.4779     0.20125    0.085122  -0.063865\n",
      " -0.17104   -0.32432   -0.17623   -0.514     -0.50289    0.23204\n",
      " -0.11324   -1.064     -0.035359  -0.5068    -0.27118   -0.16621\n",
      " -0.63016    0.054252  -0.048178   0.29282   -0.030666  -0.24645\n",
      " -0.27084   -0.42563   -0.39171    0.18428   -0.017772  -0.35334\n",
      " -0.49075   -0.90782    0.13872   -0.76521   -0.46318   -0.32124\n",
      " -0.086228   1.0448    -0.39919    0.69478   -0.10377    0.86715\n",
      "  0.22742    0.4384     0.085767  -0.22846    0.4309     0.064187\n",
      " -0.027926  -0.093056   0.65188    0.59143   -0.3376    -0.37732\n",
      "  0.0052212  1.1193    -0.23845   -0.16029    0.42877   -0.16228\n",
      " -0.12202   -0.1061     0.015761   0.022745  -0.17734   -0.091711\n",
      " -0.29158    0.19034   -0.35168    0.27563   -0.20577    0.11472\n",
      " -0.34126   -0.0065915  0.14896   -0.026762   0.0019373  0.53279\n",
      " -0.76088    0.063085  -0.72089   -0.04128   -0.96164    0.020769\n",
      "  0.16123   -0.34342    0.69713   -0.16018   -0.11701   -0.070239\n",
      " -0.30774    0.39741    0.39994   -0.678      0.57684   -0.48099\n",
      "  0.59317   -0.42262    0.28613   -0.26203    0.052727   0.61659\n",
      " -0.36801   -0.28429   -0.40054   -0.30055   -0.27444   -0.045729\n",
      " -0.56105    0.24176    0.86631   -0.83715    0.13562    0.26196\n",
      " -0.43055    0.34558    0.059441   0.61845    0.11837   -0.019168\n",
      "  0.47697   -0.32465   -0.15463   -0.23556   -0.64263   -0.092156\n",
      " -0.19622    0.40666    0.18009    0.094309   0.046917   0.26369\n",
      " -0.50727    0.37491   -0.66773    0.35095   -0.033835   0.30534\n",
      "  0.23166    0.023526  -0.68365    0.26078   -0.22526   -0.2656\n",
      "  0.59967    0.2598     0.36248    0.15564   -0.45549    0.11153\n",
      " -0.33287    0.081364  -0.36989   -0.25543   -1.1628    -0.14622\n",
      " -0.032971  -0.55619    0.47717   -0.29021    0.42688    1.2397\n",
      " -0.81391    0.21084   -0.25426   -0.08684   -0.078412   0.26035\n",
      "  0.3281    -0.23777    0.05138   -0.030247  -0.15669    0.057147\n",
      "  0.33902    0.12795   -0.21468   -0.75208    0.41422    0.0062719\n",
      " -0.52904    0.92193   -0.42179   -0.69638    0.074115   0.19071\n",
      " -1.2031    -0.081333  -0.4914    -0.22159   -0.29876    0.30094\n",
      "  0.018634   0.18786   -0.45429   -0.29296    0.3695    -0.24218\n",
      " -0.11803    0.071775   0.44026   -0.59978    0.45354    0.17854\n",
      " -0.17155    0.018811  -0.62354   -0.014163   0.16799   -0.064392 ]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Testing the GloVe model\n",
    "\n",
    "# 1. Check similar words\n",
    "print(\"Words similar to 'king':\")\n",
    "similar_words = glove_model.most_similar(\"king\", topn=10)\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")\n",
    "\n",
    "# 2. Compute word similarity\n",
    "similarity = glove_model.similarity(\"king\", \"queen\")\n",
    "print(f\"\\nSimilarity between 'king' and 'queen': {similarity:.4f}\")\n",
    "\n",
    "# 3. Perform analogy\n",
    "analogy_result = glove_model.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=1)\n",
    "print(\"\\nAnalogy result for 'king - man + woman':\", analogy_result)\n",
    "\n",
    "# 4. Check for a word in the vocabulary\n",
    "word = \"apple\"\n",
    "if word in glove_model:\n",
    "    print(f\"\\n'{word}' is in the vocabulary.\")\n",
    "else:\n",
    "    print(f\"\\n'{word}' is not in the vocabulary.\")\n",
    "\n",
    "# 5. Get word vector\n",
    "vector = glove_model[\"apple\"]\n",
    "print(\"\\nVector for 'apple':\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ac832-93ec-452b-a5f7-d25801f47d23",
   "metadata": {},
   "source": [
    "# Q1a) What is the size of the vocabulary formed from your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2f90ada-c902-439d-b1b0-c79a74f509e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16512\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    # Use simple whitespace tokenization and lowercasing\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "# Count unique tokens\n",
    "counter = Counter()\n",
    "for example in train_dataset:\n",
    "    tokens = tokenize(example[\"text\"])\n",
    "    counter.update(tokens)\n",
    "\n",
    "# Size of the vocabulary\n",
    "vocab_size = len(counter)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d39538-b899-4ca4-86b1-2c5d33444988",
   "metadata": {},
   "source": [
    "# Q1b) We use OOV (out-of-vocabulary) to refer to those words appeared in the training data but not in the Word2vec (or Glove) dictionary. How many OOV words exist in your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcde6b4c-4cd3-4754-bc23-b847b1b71d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wisegirls\n",
      "enrapturing\n",
      "compleja\n",
      "intelectualmente\n",
      "retadora\n",
      "orquídeas\n",
      "originalidad\n",
      "suspenser\n",
      "obviation\n",
      "gorefests\n",
      "waydowntown\n",
      "makmalbaf\n",
      "exhilarate\n",
      "nuttgens\n",
      "petin\n",
      "provocatuers\n",
      "jirí\n",
      "hubac\n",
      "shapelessly\n",
      "addessi\n",
      "seldahl\n",
      "wollter\n",
      "mullinski\n",
      "avventura\n",
      "needn\n",
      "narcotizing\n",
      "precollegiate\n",
      "sparklingly\n",
      "superlarge\n",
      "destinees\n",
      "margolo\n",
      "dominatrixes\n",
      "scuzbag\n",
      "idoosyncratic\n",
      "flatula\n",
      "denlopp\n",
      "updatings\n",
      "watstein\n",
      "sappier\n",
      "condensada\n",
      "divertida\n",
      "visualmente\n",
      "entretenida\n",
      "sorprenderá\n",
      "exporing\n",
      "capturou\n",
      "sarcástica\n",
      "divertida\n",
      "demencial\n",
      "predecesora\n",
      "complejos\n",
      "cadness\n",
      "shagster\n",
      "powaqqatsi\n",
      "policiales\n",
      "últimos\n",
      "kaputschnik\n",
      "kickass\n",
      "travil\n",
      "splittingly\n",
      "aborbing\n",
      "monkeyfun\n",
      "bierbichler\n",
      "crummles\n",
      "bustingly\n",
      "stultifyingly\n",
      "deutchland\n",
      "datedness\n",
      "inhospitability\n",
      "næs\n",
      "hastier\n",
      "estava\n",
      "existência\n",
      "papai\n",
      "fato\n",
      "inquestionável\n",
      "talancón\n",
      "drippiness\n",
      "seldahl\n",
      "oesn\n",
      "montias\n",
      "hotdogging\n",
      "stumblings\n",
      "birot\n",
      "apesar\n",
      "consegue\n",
      "entreter\n",
      "recoing\n",
      "bizzarre\n",
      "wollter\n",
      "seldahl\n",
      "alientation\n",
      "sogginess\n",
      "birot\n",
      "mollà\n",
      "involvingly\n",
      "wifty\n",
      "gerbosi\n",
      "stuffiest\n",
      "timewaster\n",
      "strafings\n",
      "debuter\n",
      "histo\n",
      "contando\n",
      "premissa\n",
      "mergulha\n",
      "culminando\n",
      "desfecho\n",
      "certamente\n",
      "memória\n",
      "soaringly\n",
      "entretiene\n",
      "outgag\n",
      "pulpiness\n",
      "haphazardness\n",
      "kibbitzes\n",
      "auteil\n",
      "cineasts\n",
      "intacto\n",
      "unconned\n",
      "overmanipulative\n",
      "s1m0ne\n",
      "crappola\n",
      "koshashvili\n",
      "jaglomized\n",
      "fizzability\n",
      "sytle\n",
      "decasia\n",
      "stoppingly\n",
      "waydowntown\n",
      "choquart\n",
      "espectáculo\n",
      "digno\n",
      "contemplarse\n",
      "soberbio\n",
      "montaje\n",
      "colosal\n",
      "universos\n",
      "complementares\n",
      "igualmente\n",
      "fascinantes\n",
      "captivatingly\n",
      "fillm\n",
      "unforgivingly\n",
      "unreligious\n",
      "anteing\n",
      "marcken\n",
      "mouglalis\n",
      "everlyn\n",
      "animé\n",
      "kosashvili\n",
      "idemoto\n",
      "ozpetek\n",
      "komediant\n",
      "cinemantic\n",
      "efteriades\n",
      "narcotized\n",
      "ozpetek\n",
      "graças\n",
      "às\n",
      "interações\n",
      "personagens\n",
      "divertida\n",
      "perseguição\n",
      "também\n",
      "estudo\n",
      "personagens\n",
      "contructed\n",
      "volletta\n",
      "whimsicality\n",
      "idemoto\n",
      "uncinematic\n",
      "corniest\n",
      "unslick\n",
      "uplifter\n",
      "blighter\n",
      "ozpetek\n",
      "naturedness\n",
      "hjelje\n",
      "gaï\n",
      "masterpeice\n",
      "kosashvili\n",
      "divertida\n",
      "enternecedora\n",
      "profundamente\n",
      "sincera\n",
      "románticas\n",
      "delicia\n",
      "bjorkness\n",
      "runteldat\n",
      "cletis\n",
      "musclefest\n",
      "líquido\n",
      "incoloro\n",
      "líquido\n",
      "elemento\n",
      "achronological\n",
      "copmovieland\n",
      "auteil\n",
      "sheerly\n",
      "oídos\n",
      "movilizador\n",
      "enfrentados\n",
      "deseos\n",
      "miedos\n",
      "prejuicios\n",
      "engaña\n",
      "enfrentará\n",
      "disfrutable\n",
      "prescinde\n",
      "elemento\n",
      "patriotero\n",
      "manipulador\n",
      "rintarô\n",
      "kahlories\n",
      "logra\n",
      "desarrollarse\n",
      "pretenciosas\n",
      "resultan\n",
      "truncheoning\n",
      "claustrophic\n",
      "hitchcockianism\n",
      "chabrolian\n",
      "gooeyness\n",
      "crowdpleaser\n",
      "espite\n",
      "pincel\n",
      "retrata\n",
      "fato\n",
      "constatação\n",
      "realidade\n",
      "waydowntown\n",
      "beseechingly\n",
      "seldahl\n",
      "wollter\n",
      "cativante\n",
      "representando\n",
      "direção\n",
      "contrária\n",
      "evolução\n",
      "musicais\n",
      "waydowntown\n",
      "accomodates\n",
      "cannier\n",
      "estupendamente\n",
      "actuada\n",
      "sumamente\n",
      "emotiva\n",
      "profundamente\n",
      "fílmica\n",
      "hellstenius\n",
      "suspeito\n",
      "ganha\n",
      "também\n",
      "funcionar\n",
      "esfera\n",
      "achronological\n",
      "feardotcom\n",
      "janklowicz\n",
      "democracie\n",
      "revigorates\n",
      "qutting\n",
      "luvvies\n",
      "bergmanesque\n",
      "snazziness\n",
      "nohe\n",
      "verete\n",
      "diciness\n",
      "colonics\n",
      "outré\n",
      "janklowicz\n",
      "shmear\n",
      "bornin\n",
      "plaintiveness\n",
      "unemotive\n",
      "steinis\n",
      "cletis\n",
      "swordfights\n",
      "dooper\n",
      "adorability\n",
      "materalism\n",
      "unhibited\n",
      "seldahl\n",
      "wollter\n",
      "japanimator\n",
      "achival\n",
      "flakeball\n",
      "qatsi\n",
      "atreve\n",
      "atacar\n",
      "atacarse\n",
      "duración\n",
      "precisa\n",
      "grandiosa\n",
      "conmovedora\n",
      "têm\n",
      "início\n",
      "saímos\n",
      "começamos\n",
      "acabamos\n",
      "então\n",
      "sinais\n",
      "desaponta\n",
      "hadn\n",
      "unfakable\n",
      "dreadfulness\n",
      "sheerly\n",
      "marveilleux\n",
      "heremakono\n",
      "hotsies\n",
      "preocupar\n",
      "criar\n",
      "melodramáticos\n",
      "pianista\n",
      "emocionante\n",
      "obligada\n",
      "impotentes\n",
      "daneses\n",
      "camareras\n",
      "italianas\n",
      "desee\n",
      "expresar\n",
      "kosashvili\n",
      "surehanded\n",
      "recurre\n",
      "actuación\n",
      "perdona\n",
      "guión\n",
      "mibii\n",
      "shimmeringly\n",
      "frissons\n",
      "convencional\n",
      "narrativa\n",
      "quizá\n",
      "arriesgado\n",
      "próprio\n",
      "abandone\n",
      "paródia\n",
      "utilizar\n",
      "mesmos\n",
      "clichês\n",
      "havia\n",
      "satirizado\n",
      "nonethnic\n",
      "dysfunctionally\n",
      "vulakoro\n",
      "ourside\n",
      "birot\n",
      "goombah\n",
      "dudsville\n",
      "equlibrium\n",
      "fantasti\n",
      "surfacey\n",
      "prefeminist\n",
      "shrieky\n",
      "watstein\n",
      "premisa\n",
      "francamente\n",
      "aburrido\n",
      "stortelling\n",
      "autocritique\n",
      "disposible\n",
      "artnering\n",
      "reeses\n",
      "slappingly\n",
      "eroti\n",
      "vidgame\n",
      "nebrida\n",
      "mcklusky\n",
      "minac\n",
      "pretention\n",
      "unamusing\n",
      "blutarsky\n",
      "heartwarmingly\n",
      "gasm\n",
      "unimpressively\n",
      "responsável\n",
      "direto\n",
      "artístico\n",
      "roteirista\n",
      "consegue\n",
      "sequer\n",
      "aproveitar\n",
      "pouquíssimos\n",
      "escapa\n",
      "mediocridade\n",
      "unembarrassing\n",
      "bibbidy\n",
      "bobbidi\n",
      "animé\n",
      "fluxing\n",
      "burningly\n",
      "cletis\n",
      "bottomlessly\n",
      "nohe\n",
      "halfwit\n",
      "aceitou\n",
      "continuação\n",
      "saído\n",
      "esquerdo\n",
      "aqueles\n",
      "decidiram\n",
      "assistir\n",
      "também\n",
      "toolbags\n",
      "glizty\n",
      "pistoled\n",
      "indieflick\n",
      "hammily\n",
      "cletis\n",
      "dullingly\n",
      "nonchallenging\n",
      "affirmational\n",
      "smashups\n",
      "phonce\n",
      "birot\n",
      "stuporously\n",
      "repellantly\n",
      "runteldat\n",
      "unentertaining\n",
      "decirles\n",
      "grato\n",
      "desnudo\n",
      "kalesniko\n",
      "squaddie\n",
      "waydowntown\n",
      "sandlerian\n",
      "hirosue\n",
      "actorish\n",
      "penotti\n",
      "leatherbound\n",
      "zzzzzzzzz\n",
      "hadn\n",
      "puttingly\n",
      "schneidermeister\n",
      "kidlets\n",
      "sychowski\n",
      "fustily\n",
      "feardotcom\n",
      "romething\n",
      "ricture\n",
      "prechewed\n",
      "sitcomishly\n",
      "thesps\n",
      "sillified\n",
      "italicizes\n",
      "skeeved\n",
      "skippable\n",
      "greaseballs\n",
      "forgettably\n",
      "overstylized\n",
      "puréed\n",
      "wankery\n",
      "substitutable\n",
      "leplouff\n",
      "maelström\n",
      "ventually\n",
      "gutterball\n",
      "thekids\n",
      "overplotted\n",
      "thons\n",
      "collosum\n",
      "drek\n",
      "unclassifiably\n",
      "untugged\n",
      "unplundered\n",
      "zillionth\n",
      "dateflick\n",
      "uncharismatically\n",
      "allodi\n",
      "nolden\n",
      "higuchinsky\n",
      "28k\n",
      "hamfisted\n",
      "amoses\n",
      "8217\n",
      "8217\n",
      "prewarned\n",
      "unencouraging\n",
      "nutjob\n",
      "overemphatic\n",
      "lástima\n",
      "estafeta\n",
      "puportedly\n",
      "corruscating\n",
      "inconsequentiality\n",
      "repulsively\n",
      "deadeningly\n",
      "laboriousness\n",
      "stultifyingly\n",
      "dumbfoundingly\n",
      "ooky\n",
      "spookies\n",
      "clutchy\n",
      "unrecommendable\n",
      "shayamalan\n",
      "greasiest\n",
      "solondzian\n",
      "ozpetek\n",
      "birot\n",
      "nohe\n",
      "ihops\n",
      "villians\n",
      "carente\n",
      "imaginación\n",
      "actuada\n",
      "ápice\n",
      "pérdida\n",
      "delibrately\n",
      "divertingly\n",
      "headbangingly\n",
      "fuhgeddaboutit\n",
      "russos\n",
      "wewannour\n",
      "salaciously\n",
      "dogwalker\n",
      "kazmierski\n",
      "unsuspenseful\n",
      "humbuggery\n",
      "qatsi\n",
      "lapdance\n",
      "interspliced\n",
      "russos\n",
      "siuation\n",
      "episódio\n",
      "única\n",
      "diferença\n",
      "gosto\n",
      "exibi\n",
      "meaningness\n",
      "miscasts\n",
      "hadn\n",
      "likableness\n",
      "elegiacally\n",
      "ryanovich\n",
      "brûlée\n",
      "dridi\n",
      "manqué\n",
      "nerfs\n",
      "dès\n",
      "ineptitudes\n",
      "sailboaters\n",
      "apallingly\n",
      "excrescence\n",
      "costumey\n",
      "espetáculo\n",
      "possui\n",
      "esteticamente\n",
      "emocionalmente\n",
      "nrelentingly\n",
      "slowtime\n",
      "montias\n",
      "montied\n",
      "strainingly\n",
      "gantzes\n",
      "uberviolence\n",
      "clericks\n",
      "roisterous\n",
      "birot\n",
      "gymkata\n",
      "incompetência\n",
      "roteirista\n",
      "superada\n",
      "péssima\n",
      "direção\n",
      "slummy\n",
      "kalvert\n",
      "guessable\n",
      "cletis\n",
      "inducingly\n",
      "cipherlike\n",
      "landbound\n",
      "hobnail\n",
      "psychodramatics\n",
      "sermonize\n",
      "ozpetek\n",
      "intentando\n",
      "rápidamente\n",
      "transforma\n",
      "absolutamente\n",
      "predecible\n",
      "meanspirited\n",
      "butterfingered\n",
      "coriat\n",
      "splatterfests\n",
      "ótimo\n",
      "esforço\n",
      "diretor\n",
      "frustrado\n",
      "roteiro\n",
      "colocar\n",
      "andamento\n",
      "perde\n",
      "instante\n",
      "estranhos\n",
      "acontecimentos\n",
      "explicados\n",
      "reconceptualize\n",
      "cirulnick\n",
      "artsploitation\n",
      "stagecrafts\n",
      "unsalvageability\n",
      "transfigures\n",
      "witlessness\n",
      "pollyana\n",
      "shapable\n",
      "felinni\n",
      "imponderably\n",
      "pokepie\n",
      "bruckheimeresque\n",
      "stultifyingly\n",
      "derivativeness\n",
      "versión\n",
      "preciosista\n",
      "ningún\n",
      "djeinaba\n",
      "needn\n",
      "silbersteins\n",
      "juiceless\n",
      "reeboir\n",
      "perfervid\n",
      "bondish\n",
      "underdramatized\n",
      "joylessly\n",
      "emptily\n",
      "actory\n",
      "feardotcom\n",
      "kidlets\n",
      "gabbiest\n",
      "bazadona\n",
      "tardier\n",
      "frissons\n",
      "superficiale\n",
      "flck\n",
      "chopsocky\n",
      "cletis\n",
      "fuddled\n",
      "adventues\n",
      "necessidade\n",
      "término\n",
      "projeção\n",
      "preocupe\n",
      "ninguém\n",
      "lhe\n",
      "enviará\n",
      "simbolizando\n",
      "covardia\n",
      "defeatingly\n",
      "shoplifts\n",
      "unlaughable\n",
      "5ths\n",
      "shakesperean\n",
      "amusedly\n",
      "snoots\n",
      "shlockmeister\n",
      "Number of OOV words: 655\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for example in train_dataset:\n",
    "    tokens = tokenize(example[\"text\"])\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    for token in tokens:\n",
    "        if token not in glove_model:\n",
    "            counter += 1\n",
    "            print(token)\n",
    "\n",
    "print(\"Number of OOV words:\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb29735-f027-496a-9475-796ea06d9a40",
   "metadata": {},
   "source": [
    "# Q1c) The existence of the OOV words is one of the well-known limitations of Word2vec (or Glove). Without using any transformer-based language models (e.g., BERT, GPT, T5), what do you think is the best strategy to mitigate such limitation? Implement your solution in your source code. Show the corresponding code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba73f6-d5fd-4870-b8af-41710e463d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
