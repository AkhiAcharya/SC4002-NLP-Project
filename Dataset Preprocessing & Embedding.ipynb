{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "58d8c358-fd02-4d7b-a9db-6d5bb9bf4188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.0.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.12/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (5.2.1)\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.26.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
      "  Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.26.1-cp312-cp312-macosx_11_0_arm64.whl (157 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install gensim\n",
    "!pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fbc661-1c81-42e9-8a6d-c56d5a8aad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f157e3-981a-4787-8322-5a2ead0804c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ade63b-ca74-4973-af2f-b356aef66c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  label\n",
      "0   lovingly photographed in the manner of a golde...      1\n",
      "1               consistently clever and suspenseful .      1\n",
      "2   it's like a \" big chill \" reunion of the baade...      1\n",
      "3   the story gives ample opportunity for large-sc...      1\n",
      "4                   red dragon \" never cuts corners .      1\n",
      "5   fresnadillo has something serious to say about...      1\n",
      "6   throws in enough clever and unexpected twists ...      1\n",
      "7   weighty and ponderous but every bit as filling...      1\n",
      "8   a real audience-pleaser that will strike a cho...      1\n",
      "9   generates an enormous feeling of empathy for i...      1\n",
      "10  exposing the ways we fool ourselves is one hou...      1\n",
      "11  it's up to you to decide whether to admire the...      1\n",
      "12  mostly , [goldbacher] just lets her complicate...      1\n",
      "13  . . . quite good at providing some good old fa...      1\n",
      "14  at its worst , the movie is pretty diverting ;...      1\n",
      "{'text': ['lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'consistently clever and suspenseful .', 'it\\'s like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .', 'the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .', 'red dragon \" never cuts corners .', 'fresnadillo has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense .', 'throws in enough clever and unexpected twists to make the formula feel fresh .', 'weighty and ponderous but every bit as filling as the treat of the title .', \"a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\", 'generates an enormous feeling of empathy for its characters .', \"exposing the ways we fool ourselves is one hour photo's real strength .\", \"it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful view of american life .\", 'mostly , [goldbacher] just lets her complicated characters be unruly , confusing and , through it all , human .', '. . . quite good at providing some good old fashioned spooks .', 'at its worst , the movie is pretty diverting ; the pity is that it rarely achieves its best .'], 'label': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_dataset.to_pandas().head(15))\n",
    "\n",
    "print(test_dataset[:15])  # View the first 5 rows as a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc6a14-2a1b-4c18-a271-047bd4414647",
   "metadata": {},
   "source": [
    "# Google Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff10a49d-ad95-444e-842e-3d4c952b6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded and saved at: /Users/akhi/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Define the model path\n",
    "model_name = \"word2vec-google-news-300\"\n",
    "\n",
    "path = api.load(model_name, return_path=True)\n",
    "print(f\"Model downloaded and saved at: {path}\")\n",
    "\n",
    "\n",
    "# Load the model\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b5241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "677787bc-b346-4868-b40f-e080afb3bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'king':\n",
      "kings: 0.7138\n",
      "queen: 0.6511\n",
      "monarch: 0.6413\n",
      "crown_prince: 0.6204\n",
      "prince: 0.6160\n",
      "sultan: 0.5865\n",
      "ruler: 0.5798\n",
      "princes: 0.5647\n",
      "Prince_Paras: 0.5433\n",
      "throne: 0.5422\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to \"king\"\n",
    "similar_words = word2vec_model.most_similar(\"king\", topn=10)\n",
    "print(\"Words similar to 'king':\")\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3872da37-9aaa-4cde-a2ff-bd55cd12e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'king' and 'queen': 0.6511\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity between \"king\" and \"queen\"\n",
    "similarity = word2vec_model.similarity(\"king\", \"queen\")\n",
    "print(f\"Similarity between 'king' and 'queen': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4ea02728-46a8-4830-a059-59f7cd5817ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'apple': [ 0.12597656  0.19042969  0.06982422  0.07226562 -0.21875     0.02758789\n",
      "  0.05395508 -0.07666016  0.04296875 -0.12988281  0.05151367 -0.10498047\n",
      " -0.11474609  0.05566406 -0.05029297 -0.00424194  0.08447266  0.00915527\n",
      " -0.09277344 -0.02770996  0.08935547 -0.11425781 -0.13476562 -0.09521484\n",
      " -0.10742188 -0.10888672 -0.02563477  0.31054688  0.17382812  0.19921875\n",
      "  0.0090332   0.02905273 -0.09863281 -0.10058594 -0.21191406 -0.11962891\n",
      " -0.06542969  0.125      -0.07617188 -0.11181641 -0.19726562  0.12695312\n",
      "  0.02770996  0.04785156  0.11035156  0.04760742  0.01330566  0.19726562\n",
      "  0.11962891  0.04296875  0.07861328 -0.07128906  0.21972656  0.00772095\n",
      " -0.16210938  0.125       0.10498047 -0.03588867 -0.03710938 -0.11767578\n",
      " -0.29296875  0.11669922  0.04077148 -0.00152588 -0.06445312  0.24023438\n",
      "  0.29101562 -0.03198242 -0.02160645  0.08398438  0.0703125   0.05175781\n",
      "  0.17871094 -0.05639648  0.09472656 -0.01275635  0.02050781  0.13867188\n",
      " -0.00069427  0.26757812  0.17480469 -0.13574219  0.05517578  0.14941406\n",
      "  0.05395508 -0.01611328 -0.05712891  0.23046875  0.09033203 -0.05078125\n",
      " -0.0324707  -0.02038574 -0.16113281 -0.23144531  0.08105469 -0.01318359\n",
      " -0.07617188  0.09326172 -0.22753906  0.05834961 -0.07763672 -0.19726562\n",
      " -0.18164062  0.07421875 -0.06396484  0.15136719 -0.00349426 -0.13964844\n",
      " -0.09423828 -0.29492188  0.09716797  0.0168457   0.00457764  0.05224609\n",
      "  0.140625    0.109375   -0.07714844  0.11279297  0.23632812  0.08447266\n",
      " -0.11230469 -0.13671875 -0.22167969  0.06689453 -0.04516602  0.28515625\n",
      "  0.07470703 -0.00524902  0.17578125  0.1484375  -0.12890625  0.18652344\n",
      "  0.01098633  0.01098633  0.12988281 -0.01940918  0.12597656 -0.05444336\n",
      " -0.05322266  0.16015625 -0.11865234 -0.0112915   0.10888672 -0.02575684\n",
      "  0.00836182  0.00215149 -0.06005859  0.09228516  0.03710938  0.15136719\n",
      "  0.20800781 -0.12060547 -0.04711914  0.12792969  0.09521484  0.2421875\n",
      "  0.02087402 -0.29492188 -0.10058594 -0.15917969 -0.06884766  0.1328125\n",
      " -0.11572266  0.25585938 -0.00245667 -0.02233887  0.14257812 -0.1796875\n",
      "  0.00230408  0.22265625 -0.01434326 -0.02783203  0.14648438 -0.2734375\n",
      "  0.09667969 -0.13183594  0.07080078 -0.04370117 -0.17089844  0.12158203\n",
      " -0.01495361 -0.05395508 -0.08789062 -0.01330566 -0.13378906  0.25390625\n",
      "  0.04663086 -0.02380371  0.19824219 -0.09960938 -0.04833984  0.11132812\n",
      " -0.02893066  0.14648438 -0.14550781  0.0546875  -0.11035156 -0.01165771\n",
      " -0.25585938 -0.08642578 -0.14453125  0.08789062 -0.01611328  0.19433594\n",
      "  0.09277344  0.09716797  0.03491211  0.15136719  0.12109375 -0.10253906\n",
      "  0.05175781  0.16796875  0.23535156 -0.0213623  -0.2578125  -0.04370117\n",
      "  0.10693359 -0.00540161 -0.12597656  0.15332031  0.15527344 -0.14453125\n",
      " -0.10302734 -0.1328125   0.20996094  0.24023438 -0.00112915 -0.15039062\n",
      "  0.15136719  0.16308594 -0.20117188 -0.24902344  0.25585938 -0.01013184\n",
      " -0.0625     -0.21679688  0.015625   -0.01647949  0.13867188 -0.21875\n",
      "  0.09521484 -0.15234375 -0.02502441 -0.00457764  0.01037598  0.09326172\n",
      "  0.20507812  0.03491211  0.06738281 -0.14453125  0.15917969 -0.03393555\n",
      "  0.02563477  0.05371094  0.1640625   0.12109375  0.18945312 -0.03735352\n",
      "  0.09423828  0.05566406  0.21777344 -0.00466919 -0.12255859 -0.06176758\n",
      " -0.07958984  0.20800781  0.20214844 -0.00582886 -0.10986328  0.19335938\n",
      "  0.07910156  0.06933594  0.09619141 -0.06542969  0.11816406  0.0246582\n",
      " -0.09521484 -0.00367737 -0.09570312  0.12207031 -0.05859375  0.18847656\n",
      "  0.06982422  0.07568359  0.0324707  -0.00909424 -0.04589844 -0.10253906\n",
      " -0.20996094 -0.18652344  0.0703125   0.01843262  0.04736328  0.21191406\n",
      "  0.10595703 -0.06591797  0.01940918  0.0612793   0.17285156 -0.07861328]\n"
     ]
    }
   ],
   "source": [
    "# Get the vector for the word \"apple\"\n",
    "vector = word2vec_model[\"an\"]\n",
    "print(\"Vector for 'apple':\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdba58f-ad61-4fbe-b87d-35f1db47d633",
   "metadata": {},
   "source": [
    "# GLOVE Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "13fd9a36-85fb-4cd1-afcc-22a45eb02aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "print(\"GloVe model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8dadfe6d-6282-41e2-ab17-80c72cd51661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'king':\n",
      "queen: 0.6336\n",
      "prince: 0.6197\n",
      "monarch: 0.5900\n",
      "kingdom: 0.5791\n",
      "throne: 0.5606\n",
      "ii: 0.5562\n",
      "iii: 0.5503\n",
      "crown: 0.5225\n",
      "reign: 0.5217\n",
      "kings: 0.5066\n",
      "\n",
      "Similarity between 'king' and 'queen': 0.6336\n",
      "\n",
      "Analogy result for 'king - man + woman': [('queen', 0.6713277101516724)]\n",
      "\n",
      "'apple' is in the vocabulary.\n",
      "\n",
      "Vector for 'apple': [-0.20842   -0.019668   0.063981  -0.71403   -0.21181   -0.59283\n",
      " -0.15316    0.044217   0.63289   -0.84821   -0.21129   -0.19763\n",
      "  0.19029   -0.56226    0.27126    0.23782   -0.5189    -0.24518\n",
      "  0.035243   0.096833   0.24898    0.71279    0.038279  -0.10514\n",
      " -0.4779    -0.39515   -0.27194   -0.44428    0.06113   -0.2318\n",
      " -0.35901   -0.18239    0.035507  -0.087719  -1.0816    -0.42521\n",
      "  0.003224  -0.45991   -0.043462  -0.39031    0.519      0.21139\n",
      " -0.25527    1.1805    -0.19041   -0.12156    0.034186  -0.062316\n",
      "  0.14421   -0.53366    0.47425   -0.4471     0.58047    0.43578\n",
      "  0.1321    -0.095712  -0.37182   -0.013837   0.20601   -0.10099\n",
      "  0.10685   -0.33723    0.10986    0.34796   -0.099839   0.36942\n",
      " -0.52917    0.12407   -0.46127   -0.38483   -0.10114   -0.17634\n",
      "  0.37574    0.16377   -0.2198    -0.26841    0.84706   -0.35619\n",
      " -0.083992  -0.20276   -0.56542    0.19112   -0.14134   -0.7812\n",
      "  0.69188   -0.083628  -0.54293    0.16437    0.037606  -0.68896\n",
      " -0.68711   -0.13367   -0.4779     0.20125    0.085122  -0.063865\n",
      " -0.17104   -0.32432   -0.17623   -0.514     -0.50289    0.23204\n",
      " -0.11324   -1.064     -0.035359  -0.5068    -0.27118   -0.16621\n",
      " -0.63016    0.054252  -0.048178   0.29282   -0.030666  -0.24645\n",
      " -0.27084   -0.42563   -0.39171    0.18428   -0.017772  -0.35334\n",
      " -0.49075   -0.90782    0.13872   -0.76521   -0.46318   -0.32124\n",
      " -0.086228   1.0448    -0.39919    0.69478   -0.10377    0.86715\n",
      "  0.22742    0.4384     0.085767  -0.22846    0.4309     0.064187\n",
      " -0.027926  -0.093056   0.65188    0.59143   -0.3376    -0.37732\n",
      "  0.0052212  1.1193    -0.23845   -0.16029    0.42877   -0.16228\n",
      " -0.12202   -0.1061     0.015761   0.022745  -0.17734   -0.091711\n",
      " -0.29158    0.19034   -0.35168    0.27563   -0.20577    0.11472\n",
      " -0.34126   -0.0065915  0.14896   -0.026762   0.0019373  0.53279\n",
      " -0.76088    0.063085  -0.72089   -0.04128   -0.96164    0.020769\n",
      "  0.16123   -0.34342    0.69713   -0.16018   -0.11701   -0.070239\n",
      " -0.30774    0.39741    0.39994   -0.678      0.57684   -0.48099\n",
      "  0.59317   -0.42262    0.28613   -0.26203    0.052727   0.61659\n",
      " -0.36801   -0.28429   -0.40054   -0.30055   -0.27444   -0.045729\n",
      " -0.56105    0.24176    0.86631   -0.83715    0.13562    0.26196\n",
      " -0.43055    0.34558    0.059441   0.61845    0.11837   -0.019168\n",
      "  0.47697   -0.32465   -0.15463   -0.23556   -0.64263   -0.092156\n",
      " -0.19622    0.40666    0.18009    0.094309   0.046917   0.26369\n",
      " -0.50727    0.37491   -0.66773    0.35095   -0.033835   0.30534\n",
      "  0.23166    0.023526  -0.68365    0.26078   -0.22526   -0.2656\n",
      "  0.59967    0.2598     0.36248    0.15564   -0.45549    0.11153\n",
      " -0.33287    0.081364  -0.36989   -0.25543   -1.1628    -0.14622\n",
      " -0.032971  -0.55619    0.47717   -0.29021    0.42688    1.2397\n",
      " -0.81391    0.21084   -0.25426   -0.08684   -0.078412   0.26035\n",
      "  0.3281    -0.23777    0.05138   -0.030247  -0.15669    0.057147\n",
      "  0.33902    0.12795   -0.21468   -0.75208    0.41422    0.0062719\n",
      " -0.52904    0.92193   -0.42179   -0.69638    0.074115   0.19071\n",
      " -1.2031    -0.081333  -0.4914    -0.22159   -0.29876    0.30094\n",
      "  0.018634   0.18786   -0.45429   -0.29296    0.3695    -0.24218\n",
      " -0.11803    0.071775   0.44026   -0.59978    0.45354    0.17854\n",
      " -0.17155    0.018811  -0.62354   -0.014163   0.16799   -0.064392 ]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Testing the GloVe model\n",
    "\n",
    "# 1. Check similar words\n",
    "print(\"Words similar to 'king':\")\n",
    "similar_words = glove_model.most_similar(\"king\", topn=10)\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")\n",
    "\n",
    "# 2. Compute word similarity\n",
    "similarity = glove_model.similarity(\"king\", \"queen\")\n",
    "print(f\"\\nSimilarity between 'king' and 'queen': {similarity:.4f}\")\n",
    "\n",
    "# 3. Perform analogy\n",
    "analogy_result = glove_model.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=1)\n",
    "print(\"\\nAnalogy result for 'king - man + woman':\", analogy_result)\n",
    "\n",
    "# 4. Check for a word in the vocabulary\n",
    "word = \"apple\"\n",
    "if word in glove_model:\n",
    "    print(f\"\\n'{word}' is in the vocabulary.\")\n",
    "else:\n",
    "    print(f\"\\n'{word}' is not in the vocabulary.\")\n",
    "\n",
    "# 5. Get word vector\n",
    "vector = glove_model[\"apple\"]\n",
    "print(\"\\nVector for 'apple':\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ac832-93ec-452b-a5f7-d25801f47d23",
   "metadata": {},
   "source": [
    "# Q1a) What is the size of the vocabulary formed from your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e2f90ada-c902-439d-b1b0-c79a74f509e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16512\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    # Use simple whitespace tokenization and lowercasing\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "# Count unique tokens\n",
    "counter = Counter()\n",
    "for example in train_dataset:\n",
    "    tokens = tokenize(example[\"text\"])\n",
    "    counter.update(tokens)\n",
    "\n",
    "# Size of the vocabulary\n",
    "vocab_size = len(counter)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d39538-b899-4ca4-86b1-2c5d33444988",
   "metadata": {},
   "source": [
    "# Q1b) We use OOV (out-of-vocabulary) to refer to those words appeared in the training data but not in the Word2vec (or Glove) dictionary. How many OOV words exist in your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dcde6b4c-4cd3-4754-bc23-b847b1b71d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wisegirls\n",
      "enrapturing\n",
      "compleja\n",
      "intelectualmente\n",
      "retadora\n",
      "orquídeas\n",
      "originalidad\n",
      "suspenser\n",
      "obviation\n",
      "gorefests\n",
      "waydowntown\n",
      "makmalbaf\n",
      "exhilarate\n",
      "nuttgens\n",
      "petin\n",
      "provocatuers\n",
      "jirí\n",
      "hubac\n",
      "shapelessly\n",
      "addessi\n",
      "seldahl\n",
      "wollter\n",
      "mullinski\n",
      "avventura\n",
      "needn\n",
      "narcotizing\n",
      "precollegiate\n",
      "sparklingly\n",
      "superlarge\n",
      "destinees\n",
      "margolo\n",
      "dominatrixes\n",
      "scuzbag\n",
      "idoosyncratic\n",
      "flatula\n",
      "denlopp\n",
      "updatings\n",
      "watstein\n",
      "sappier\n",
      "condensada\n",
      "divertida\n",
      "visualmente\n",
      "entretenida\n",
      "sorprenderá\n",
      "exporing\n",
      "capturou\n",
      "sarcástica\n",
      "divertida\n",
      "demencial\n",
      "predecesora\n",
      "complejos\n",
      "cadness\n",
      "shagster\n",
      "powaqqatsi\n",
      "policiales\n",
      "últimos\n",
      "kaputschnik\n",
      "kickass\n",
      "travil\n",
      "splittingly\n",
      "aborbing\n",
      "monkeyfun\n",
      "bierbichler\n",
      "crummles\n",
      "bustingly\n",
      "stultifyingly\n",
      "deutchland\n",
      "datedness\n",
      "inhospitability\n",
      "næs\n",
      "hastier\n",
      "estava\n",
      "existência\n",
      "papai\n",
      "fato\n",
      "inquestionável\n",
      "talancón\n",
      "drippiness\n",
      "seldahl\n",
      "oesn\n",
      "montias\n",
      "hotdogging\n",
      "stumblings\n",
      "birot\n",
      "apesar\n",
      "consegue\n",
      "entreter\n",
      "recoing\n",
      "bizzarre\n",
      "wollter\n",
      "seldahl\n",
      "alientation\n",
      "sogginess\n",
      "birot\n",
      "mollà\n",
      "involvingly\n",
      "wifty\n",
      "gerbosi\n",
      "stuffiest\n",
      "timewaster\n",
      "strafings\n",
      "debuter\n",
      "histo\n",
      "contando\n",
      "premissa\n",
      "mergulha\n",
      "culminando\n",
      "desfecho\n",
      "certamente\n",
      "memória\n",
      "soaringly\n",
      "entretiene\n",
      "outgag\n",
      "pulpiness\n",
      "haphazardness\n",
      "kibbitzes\n",
      "auteil\n",
      "cineasts\n",
      "intacto\n",
      "unconned\n",
      "overmanipulative\n",
      "s1m0ne\n",
      "crappola\n",
      "koshashvili\n",
      "jaglomized\n",
      "fizzability\n",
      "sytle\n",
      "decasia\n",
      "stoppingly\n",
      "waydowntown\n",
      "choquart\n",
      "espectáculo\n",
      "digno\n",
      "contemplarse\n",
      "soberbio\n",
      "montaje\n",
      "colosal\n",
      "universos\n",
      "complementares\n",
      "igualmente\n",
      "fascinantes\n",
      "captivatingly\n",
      "fillm\n",
      "unforgivingly\n",
      "unreligious\n",
      "anteing\n",
      "marcken\n",
      "mouglalis\n",
      "everlyn\n",
      "animé\n",
      "kosashvili\n",
      "idemoto\n",
      "ozpetek\n",
      "komediant\n",
      "cinemantic\n",
      "efteriades\n",
      "narcotized\n",
      "ozpetek\n",
      "graças\n",
      "às\n",
      "interações\n",
      "personagens\n",
      "divertida\n",
      "perseguição\n",
      "também\n",
      "estudo\n",
      "personagens\n",
      "contructed\n",
      "volletta\n",
      "whimsicality\n",
      "idemoto\n",
      "uncinematic\n",
      "corniest\n",
      "unslick\n",
      "uplifter\n",
      "blighter\n",
      "ozpetek\n",
      "naturedness\n",
      "hjelje\n",
      "gaï\n",
      "masterpeice\n",
      "kosashvili\n",
      "divertida\n",
      "enternecedora\n",
      "profundamente\n",
      "sincera\n",
      "románticas\n",
      "delicia\n",
      "bjorkness\n",
      "runteldat\n",
      "cletis\n",
      "musclefest\n",
      "líquido\n",
      "incoloro\n",
      "líquido\n",
      "elemento\n",
      "achronological\n",
      "copmovieland\n",
      "auteil\n",
      "sheerly\n",
      "oídos\n",
      "movilizador\n",
      "enfrentados\n",
      "deseos\n",
      "miedos\n",
      "prejuicios\n",
      "engaña\n",
      "enfrentará\n",
      "disfrutable\n",
      "prescinde\n",
      "elemento\n",
      "patriotero\n",
      "manipulador\n",
      "rintarô\n",
      "kahlories\n",
      "logra\n",
      "desarrollarse\n",
      "pretenciosas\n",
      "resultan\n",
      "truncheoning\n",
      "claustrophic\n",
      "hitchcockianism\n",
      "chabrolian\n",
      "gooeyness\n",
      "crowdpleaser\n",
      "espite\n",
      "pincel\n",
      "retrata\n",
      "fato\n",
      "constatação\n",
      "realidade\n",
      "waydowntown\n",
      "beseechingly\n",
      "seldahl\n",
      "wollter\n",
      "cativante\n",
      "representando\n",
      "direção\n",
      "contrária\n",
      "evolução\n",
      "musicais\n",
      "waydowntown\n",
      "accomodates\n",
      "cannier\n",
      "estupendamente\n",
      "actuada\n",
      "sumamente\n",
      "emotiva\n",
      "profundamente\n",
      "fílmica\n",
      "hellstenius\n",
      "suspeito\n",
      "ganha\n",
      "também\n",
      "funcionar\n",
      "esfera\n",
      "achronological\n",
      "feardotcom\n",
      "janklowicz\n",
      "democracie\n",
      "revigorates\n",
      "qutting\n",
      "luvvies\n",
      "bergmanesque\n",
      "snazziness\n",
      "nohe\n",
      "verete\n",
      "diciness\n",
      "colonics\n",
      "outré\n",
      "janklowicz\n",
      "shmear\n",
      "bornin\n",
      "plaintiveness\n",
      "unemotive\n",
      "steinis\n",
      "cletis\n",
      "swordfights\n",
      "dooper\n",
      "adorability\n",
      "materalism\n",
      "unhibited\n",
      "seldahl\n",
      "wollter\n",
      "japanimator\n",
      "achival\n",
      "flakeball\n",
      "qatsi\n",
      "atreve\n",
      "atacar\n",
      "atacarse\n",
      "duración\n",
      "precisa\n",
      "grandiosa\n",
      "conmovedora\n",
      "têm\n",
      "início\n",
      "saímos\n",
      "começamos\n",
      "acabamos\n",
      "então\n",
      "sinais\n",
      "desaponta\n",
      "hadn\n",
      "unfakable\n",
      "dreadfulness\n",
      "sheerly\n",
      "marveilleux\n",
      "heremakono\n",
      "hotsies\n",
      "preocupar\n",
      "criar\n",
      "melodramáticos\n",
      "pianista\n",
      "emocionante\n",
      "obligada\n",
      "impotentes\n",
      "daneses\n",
      "camareras\n",
      "italianas\n",
      "desee\n",
      "expresar\n",
      "kosashvili\n",
      "surehanded\n",
      "recurre\n",
      "actuación\n",
      "perdona\n",
      "guión\n",
      "mibii\n",
      "shimmeringly\n",
      "frissons\n",
      "convencional\n",
      "narrativa\n",
      "quizá\n",
      "arriesgado\n",
      "próprio\n",
      "abandone\n",
      "paródia\n",
      "utilizar\n",
      "mesmos\n",
      "clichês\n",
      "havia\n",
      "satirizado\n",
      "nonethnic\n",
      "dysfunctionally\n",
      "vulakoro\n",
      "ourside\n",
      "birot\n",
      "goombah\n",
      "dudsville\n",
      "equlibrium\n",
      "fantasti\n",
      "surfacey\n",
      "prefeminist\n",
      "shrieky\n",
      "watstein\n",
      "premisa\n",
      "francamente\n",
      "aburrido\n",
      "stortelling\n",
      "autocritique\n",
      "disposible\n",
      "artnering\n",
      "reeses\n",
      "slappingly\n",
      "eroti\n",
      "vidgame\n",
      "nebrida\n",
      "mcklusky\n",
      "minac\n",
      "pretention\n",
      "unamusing\n",
      "blutarsky\n",
      "heartwarmingly\n",
      "gasm\n",
      "unimpressively\n",
      "responsável\n",
      "direto\n",
      "artístico\n",
      "roteirista\n",
      "consegue\n",
      "sequer\n",
      "aproveitar\n",
      "pouquíssimos\n",
      "escapa\n",
      "mediocridade\n",
      "unembarrassing\n",
      "bibbidy\n",
      "bobbidi\n",
      "animé\n",
      "fluxing\n",
      "burningly\n",
      "cletis\n",
      "bottomlessly\n",
      "nohe\n",
      "halfwit\n",
      "aceitou\n",
      "continuação\n",
      "saído\n",
      "esquerdo\n",
      "aqueles\n",
      "decidiram\n",
      "assistir\n",
      "também\n",
      "toolbags\n",
      "glizty\n",
      "pistoled\n",
      "indieflick\n",
      "hammily\n",
      "cletis\n",
      "dullingly\n",
      "nonchallenging\n",
      "affirmational\n",
      "smashups\n",
      "phonce\n",
      "birot\n",
      "stuporously\n",
      "repellantly\n",
      "runteldat\n",
      "unentertaining\n",
      "decirles\n",
      "grato\n",
      "desnudo\n",
      "kalesniko\n",
      "squaddie\n",
      "waydowntown\n",
      "sandlerian\n",
      "hirosue\n",
      "actorish\n",
      "penotti\n",
      "leatherbound\n",
      "zzzzzzzzz\n",
      "hadn\n",
      "puttingly\n",
      "schneidermeister\n",
      "kidlets\n",
      "sychowski\n",
      "fustily\n",
      "feardotcom\n",
      "romething\n",
      "ricture\n",
      "prechewed\n",
      "sitcomishly\n",
      "thesps\n",
      "sillified\n",
      "italicizes\n",
      "skeeved\n",
      "skippable\n",
      "greaseballs\n",
      "forgettably\n",
      "overstylized\n",
      "puréed\n",
      "wankery\n",
      "substitutable\n",
      "leplouff\n",
      "maelström\n",
      "ventually\n",
      "gutterball\n",
      "thekids\n",
      "overplotted\n",
      "thons\n",
      "collosum\n",
      "drek\n",
      "unclassifiably\n",
      "untugged\n",
      "unplundered\n",
      "zillionth\n",
      "dateflick\n",
      "uncharismatically\n",
      "allodi\n",
      "nolden\n",
      "higuchinsky\n",
      "28k\n",
      "hamfisted\n",
      "amoses\n",
      "8217\n",
      "8217\n",
      "prewarned\n",
      "unencouraging\n",
      "nutjob\n",
      "overemphatic\n",
      "lástima\n",
      "estafeta\n",
      "puportedly\n",
      "corruscating\n",
      "inconsequentiality\n",
      "repulsively\n",
      "deadeningly\n",
      "laboriousness\n",
      "stultifyingly\n",
      "dumbfoundingly\n",
      "ooky\n",
      "spookies\n",
      "clutchy\n",
      "unrecommendable\n",
      "shayamalan\n",
      "greasiest\n",
      "solondzian\n",
      "ozpetek\n",
      "birot\n",
      "nohe\n",
      "ihops\n",
      "villians\n",
      "carente\n",
      "imaginación\n",
      "actuada\n",
      "ápice\n",
      "pérdida\n",
      "delibrately\n",
      "divertingly\n",
      "headbangingly\n",
      "fuhgeddaboutit\n",
      "russos\n",
      "wewannour\n",
      "salaciously\n",
      "dogwalker\n",
      "kazmierski\n",
      "unsuspenseful\n",
      "humbuggery\n",
      "qatsi\n",
      "lapdance\n",
      "interspliced\n",
      "russos\n",
      "siuation\n",
      "episódio\n",
      "única\n",
      "diferença\n",
      "gosto\n",
      "exibi\n",
      "meaningness\n",
      "miscasts\n",
      "hadn\n",
      "likableness\n",
      "elegiacally\n",
      "ryanovich\n",
      "brûlée\n",
      "dridi\n",
      "manqué\n",
      "nerfs\n",
      "dès\n",
      "ineptitudes\n",
      "sailboaters\n",
      "apallingly\n",
      "excrescence\n",
      "costumey\n",
      "espetáculo\n",
      "possui\n",
      "esteticamente\n",
      "emocionalmente\n",
      "nrelentingly\n",
      "slowtime\n",
      "montias\n",
      "montied\n",
      "strainingly\n",
      "gantzes\n",
      "uberviolence\n",
      "clericks\n",
      "roisterous\n",
      "birot\n",
      "gymkata\n",
      "incompetência\n",
      "roteirista\n",
      "superada\n",
      "péssima\n",
      "direção\n",
      "slummy\n",
      "kalvert\n",
      "guessable\n",
      "cletis\n",
      "inducingly\n",
      "cipherlike\n",
      "landbound\n",
      "hobnail\n",
      "psychodramatics\n",
      "sermonize\n",
      "ozpetek\n",
      "intentando\n",
      "rápidamente\n",
      "transforma\n",
      "absolutamente\n",
      "predecible\n",
      "meanspirited\n",
      "butterfingered\n",
      "coriat\n",
      "splatterfests\n",
      "ótimo\n",
      "esforço\n",
      "diretor\n",
      "frustrado\n",
      "roteiro\n",
      "colocar\n",
      "andamento\n",
      "perde\n",
      "instante\n",
      "estranhos\n",
      "acontecimentos\n",
      "explicados\n",
      "reconceptualize\n",
      "cirulnick\n",
      "artsploitation\n",
      "stagecrafts\n",
      "unsalvageability\n",
      "transfigures\n",
      "witlessness\n",
      "pollyana\n",
      "shapable\n",
      "felinni\n",
      "imponderably\n",
      "pokepie\n",
      "bruckheimeresque\n",
      "stultifyingly\n",
      "derivativeness\n",
      "versión\n",
      "preciosista\n",
      "ningún\n",
      "djeinaba\n",
      "needn\n",
      "silbersteins\n",
      "juiceless\n",
      "reeboir\n",
      "perfervid\n",
      "bondish\n",
      "underdramatized\n",
      "joylessly\n",
      "emptily\n",
      "actory\n",
      "feardotcom\n",
      "kidlets\n",
      "gabbiest\n",
      "bazadona\n",
      "tardier\n",
      "frissons\n",
      "superficiale\n",
      "flck\n",
      "chopsocky\n",
      "cletis\n",
      "fuddled\n",
      "adventues\n",
      "necessidade\n",
      "término\n",
      "projeção\n",
      "preocupe\n",
      "ninguém\n",
      "lhe\n",
      "enviará\n",
      "simbolizando\n",
      "covardia\n",
      "defeatingly\n",
      "shoplifts\n",
      "unlaughable\n",
      "5ths\n",
      "shakesperean\n",
      "amusedly\n",
      "snoots\n",
      "shlockmeister\n",
      "Number of OOV words: 655\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for example in train_dataset:\n",
    "    tokens = tokenize(example[\"text\"])\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    for token in tokens:\n",
    "        if token not in glove_model:\n",
    "            counter += 1\n",
    "            print(token)\n",
    "\n",
    "print(\"Number of OOV words:\", counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb29735-f027-496a-9475-796ea06d9a40",
   "metadata": {},
   "source": [
    "# Q1c) The existence of the OOV words is one of the well-known limitations of Word2vec (or Glove). Without using any transformer-based language models (e.g., BERT, GPT, T5), what do you think is the best strategy to mitigate such limitation? Implement your solution in your source code. Show the corresponding code snippet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc018cf9-038d-4967-8b73-c59150e4492e",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "72285381-1b5b-4056-ad26-6ddf61419160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load FastText model for OOV handling\n",
    "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "print(\"FastText model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e0ba73f6-d5fd-4870-b8af-41710e463d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'computer': [-0.27628   0.13999   0.098519 -0.64019   0.031988]...\n",
      "Word 'datascientist' not found in either GloVe or FastText. Generating random embedding.\n",
      "Embedding for 'datascientist': [0.3411798  0.15531629 0.5699988  0.69916882 0.27357539]...\n",
      "Word 'qwertyuiop' not found in either GloVe or FastText. Generating random embedding.\n",
      "Embedding for 'qwertyuiop': [0.40632766 0.21124225 0.97227036 0.67743276 0.98819265]...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "oov_words_vectors = {}\n",
    "\n",
    "# Function to retrieve embedding, handling OOV words as well\n",
    "def get_embedding(word, oov_vector_size=300):\n",
    "    \"\"\"\n",
    "    Get the embedding of a word:\n",
    "      - First try GloVe\n",
    "      - Then FastText\n",
    "      - Finally, generate a random vector if not found in either\n",
    "    \"\"\"\n",
    "    \n",
    "    if word in glove_model:\n",
    "        return glove_model[word]\n",
    "\n",
    "    elif word in fasttext_model:\n",
    "        print(f\"OOV word '{word}' found in FastText model.\")\n",
    "        return fasttext_model[word]\n",
    "\n",
    "    else:\n",
    "        print(f\"Word '{word}' not found in either GloVe or FastText. Generating random embedding.\")\n",
    "        if word not in oov_words_vectors:\n",
    "            oov_words_vectors[word] = np.random.rand(oov_vector_size)\n",
    "        return oov_words_vectors[word]\n",
    "\n",
    "# Example usage\n",
    "words = [\"computer\", \"datascientist\", \"qwertyuiop\"]  \n",
    "for word in words:\n",
    "    embedding = get_embedding(word)\n",
    "    if embedding is not None:\n",
    "        print(f\"Embedding for '{word}': {embedding[:5]}...\")  # Displaying first 5 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f54532-cdb0-4248-a00d-45b83962bd1b",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bba875-fff7-4527-b63b-7a2c8f6f1230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e95fb-b4dd-4d91-a45f-2539618076be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
